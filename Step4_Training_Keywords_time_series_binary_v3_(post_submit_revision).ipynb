{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SiMori92/reddit-NLP/blob/main/Step4_Training_Keywords_time_series_binary_v3_(post_submit_revision).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem we solve:\n",
        "- Correlation between Reddit comment and Stock market performance"
      ],
      "metadata": {
        "id": "NNJWny3Iki9f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Content\n",
        "\n",
        "- Pre1: load library\n",
        "- Pre2: load data\n",
        "  - split training set & testing set\n",
        "1. Training\n",
        "  1. models\n",
        "    - SVM\n",
        "    - Gaussian Naive Bayes\n",
        "    - Random Forest\n",
        "    - XGBoost\n",
        "    - KNN\n",
        "    - Perceptron\n",
        "    - Stochastic Gradient Descent (SGD)\n",
        "2. Evaluation\n",
        "  1. Accuracy\n",
        "  2. F1\n",
        "3. Analysis"
      ],
      "metadata": {
        "id": "B4vKdmJmpEfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QQ62NW4AWZV",
        "outputId": "cd93d772-6d85-416b-c4a9-ab47669fdbbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VINLIeuwiCOi"
      },
      "outputs": [],
      "source": [
        "# import library\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import re\n",
        "import string\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Libraries for text preprocessing.\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.probability import FreqDist\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "!pip install bert-tensorflow\n",
        "from bert import tokenization\n",
        "\n",
        "from wordcloud import STOPWORDS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAk_gKxst_bf",
        "outputId": "e7ec09e0-232e-4c1b-854b-29debc3a0c6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bert-tensorflow\n",
            "  Downloading bert_tensorflow-1.0.4-py2.py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.4/64.4 kB\u001b[0m \u001b[31m669.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from bert-tensorflow) (1.16.0)\n",
            "Installing collected packages: bert-tensorflow\n",
            "Successfully installed bert-tensorflow-1.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #load traing features\n",
        "\n",
        "X_train_binary = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/CUSCS/CUSCS - final project/data/X_train_binary_Oct22-Jun23.csv\", index_col=0)\n",
        "\n",
        "X_test_binary = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/CUSCS/CUSCS - final project/data/X_test_binary_Oct22-Jun23.csv\", index_col=0)\n",
        "\n",
        "Train_labels_df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/CUSCS/CUSCS - final project/data/Y_train_binary_Oct22-Jun23.csv\", index_col=0)\n",
        "\n",
        "Test_labels_df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/CUSCS/CUSCS - final project/data/Y_test_binary_Oct22-Jun23.csv\", index_col=0)\n",
        "\n",
        "X_train_binary\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "id": "D2AdsE3uubfS",
        "outputId": "6d04ad81-627d-4caf-be5d-5c79d31807e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Positive Score  Neutral Score  Negative Score   Volume_NQ  \\\n",
              "date                                                                    \n",
              "2022-07-13     5024.359219    5678.274264     4083.893385  4109390000   \n",
              "2022-07-14     4844.542607    5532.941506     3947.415250  4199690000   \n",
              "2022-07-15     5196.744694    5936.066150     4100.179924  4143800000   \n",
              "2022-07-19     4271.226150    4895.476156     3544.895066  4041070000   \n",
              "2022-07-20     5478.581053    6209.195254     4376.094286  4185300000   \n",
              "...                    ...            ...             ...         ...   \n",
              "2023-04-25     2804.523721    3157.972777     2268.912828  3978640000   \n",
              "2023-04-26     3928.897786    4420.336524     3169.792346  3837030000   \n",
              "2023-04-27     3117.071916    3533.111601     2482.705836  3750550000   \n",
              "2023-04-28     3874.279091    4336.781289     3091.032770  4087800000   \n",
              "2023-05-01     2038.911417    2278.779337     1596.856390  3321370000   \n",
              "\n",
              "            Positive Score_lag1  Positive Score_lag2  Neutral Score_lag1  \\\n",
              "date                                                                       \n",
              "2022-07-13          3776.735609          3776.076531         4296.107199   \n",
              "2022-07-14          5024.359219          3776.076531         5678.274264   \n",
              "2022-07-15          4844.542607          5024.359219         5532.941506   \n",
              "2022-07-19          5196.744694          4844.542607         5936.066150   \n",
              "2022-07-20          4271.226150          5196.744694         4895.476156   \n",
              "...                         ...                  ...                 ...   \n",
              "2023-04-25          2104.656566          2198.441592         2392.546549   \n",
              "2023-04-26          2804.523721          2104.656566         3157.972777   \n",
              "2023-04-27          3928.897786          2804.523721         4420.336524   \n",
              "2023-04-28          3117.071916          3928.897786         3533.111601   \n",
              "2023-05-01          3874.279091          3117.071916         4336.781289   \n",
              "\n",
              "            Neutral Score_lag2  Negative Score_lag1  Negative Score_lag2  \\\n",
              "date                                                                       \n",
              "2022-07-13         4295.832374          3074.200317          3074.086584   \n",
              "2022-07-14         4295.832374          4083.893385          3074.086584   \n",
              "2022-07-15         5678.274264          3947.415250          4083.893385   \n",
              "2022-07-19         5532.941506          4100.179924          3947.415250   \n",
              "2022-07-20         5936.066150          3544.895066          4100.179924   \n",
              "...                        ...                  ...                  ...   \n",
              "2023-04-25         2522.740930          1688.785950          1801.110241   \n",
              "2023-04-26         2392.546549          2268.912828          1688.785950   \n",
              "2023-04-27         3157.972777          3169.792346          2268.912828   \n",
              "2023-04-28         4420.336524          2482.705836          3169.792346   \n",
              "2023-05-01         3533.111601          3091.032770          2482.705836   \n",
              "\n",
              "            Volume_NQ_lag1  Volume_NQ_lag2  \n",
              "date                                        \n",
              "2022-07-13    4.288924e+09    4.290283e+09  \n",
              "2022-07-14    4.109390e+09    4.290283e+09  \n",
              "2022-07-15    4.199690e+09    4.109390e+09  \n",
              "2022-07-19    4.143800e+09    4.199690e+09  \n",
              "2022-07-20    4.041070e+09    4.143800e+09  \n",
              "...                    ...             ...  \n",
              "2023-04-25    3.290940e+09    3.611750e+09  \n",
              "2023-04-26    3.978640e+09    3.290940e+09  \n",
              "2023-04-27    3.837030e+09    3.978640e+09  \n",
              "2023-04-28    3.750550e+09    3.837030e+09  \n",
              "2023-05-01    4.087800e+09    3.750550e+09  \n",
              "\n",
              "[150 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f339da27-b68c-48e1-82dd-8f8be00f3d84\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Positive Score</th>\n",
              "      <th>Neutral Score</th>\n",
              "      <th>Negative Score</th>\n",
              "      <th>Volume_NQ</th>\n",
              "      <th>Positive Score_lag1</th>\n",
              "      <th>Positive Score_lag2</th>\n",
              "      <th>Neutral Score_lag1</th>\n",
              "      <th>Neutral Score_lag2</th>\n",
              "      <th>Negative Score_lag1</th>\n",
              "      <th>Negative Score_lag2</th>\n",
              "      <th>Volume_NQ_lag1</th>\n",
              "      <th>Volume_NQ_lag2</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2022-07-13</th>\n",
              "      <td>5024.359219</td>\n",
              "      <td>5678.274264</td>\n",
              "      <td>4083.893385</td>\n",
              "      <td>4109390000</td>\n",
              "      <td>3776.735609</td>\n",
              "      <td>3776.076531</td>\n",
              "      <td>4296.107199</td>\n",
              "      <td>4295.832374</td>\n",
              "      <td>3074.200317</td>\n",
              "      <td>3074.086584</td>\n",
              "      <td>4.288924e+09</td>\n",
              "      <td>4.290283e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-07-14</th>\n",
              "      <td>4844.542607</td>\n",
              "      <td>5532.941506</td>\n",
              "      <td>3947.415250</td>\n",
              "      <td>4199690000</td>\n",
              "      <td>5024.359219</td>\n",
              "      <td>3776.076531</td>\n",
              "      <td>5678.274264</td>\n",
              "      <td>4295.832374</td>\n",
              "      <td>4083.893385</td>\n",
              "      <td>3074.086584</td>\n",
              "      <td>4.109390e+09</td>\n",
              "      <td>4.290283e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-07-15</th>\n",
              "      <td>5196.744694</td>\n",
              "      <td>5936.066150</td>\n",
              "      <td>4100.179924</td>\n",
              "      <td>4143800000</td>\n",
              "      <td>4844.542607</td>\n",
              "      <td>5024.359219</td>\n",
              "      <td>5532.941506</td>\n",
              "      <td>5678.274264</td>\n",
              "      <td>3947.415250</td>\n",
              "      <td>4083.893385</td>\n",
              "      <td>4.199690e+09</td>\n",
              "      <td>4.109390e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-07-19</th>\n",
              "      <td>4271.226150</td>\n",
              "      <td>4895.476156</td>\n",
              "      <td>3544.895066</td>\n",
              "      <td>4041070000</td>\n",
              "      <td>5196.744694</td>\n",
              "      <td>4844.542607</td>\n",
              "      <td>5936.066150</td>\n",
              "      <td>5532.941506</td>\n",
              "      <td>4100.179924</td>\n",
              "      <td>3947.415250</td>\n",
              "      <td>4.143800e+09</td>\n",
              "      <td>4.199690e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-07-20</th>\n",
              "      <td>5478.581053</td>\n",
              "      <td>6209.195254</td>\n",
              "      <td>4376.094286</td>\n",
              "      <td>4185300000</td>\n",
              "      <td>4271.226150</td>\n",
              "      <td>5196.744694</td>\n",
              "      <td>4895.476156</td>\n",
              "      <td>5936.066150</td>\n",
              "      <td>3544.895066</td>\n",
              "      <td>4100.179924</td>\n",
              "      <td>4.041070e+09</td>\n",
              "      <td>4.143800e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-04-25</th>\n",
              "      <td>2804.523721</td>\n",
              "      <td>3157.972777</td>\n",
              "      <td>2268.912828</td>\n",
              "      <td>3978640000</td>\n",
              "      <td>2104.656566</td>\n",
              "      <td>2198.441592</td>\n",
              "      <td>2392.546549</td>\n",
              "      <td>2522.740930</td>\n",
              "      <td>1688.785950</td>\n",
              "      <td>1801.110241</td>\n",
              "      <td>3.290940e+09</td>\n",
              "      <td>3.611750e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-04-26</th>\n",
              "      <td>3928.897786</td>\n",
              "      <td>4420.336524</td>\n",
              "      <td>3169.792346</td>\n",
              "      <td>3837030000</td>\n",
              "      <td>2804.523721</td>\n",
              "      <td>2104.656566</td>\n",
              "      <td>3157.972777</td>\n",
              "      <td>2392.546549</td>\n",
              "      <td>2268.912828</td>\n",
              "      <td>1688.785950</td>\n",
              "      <td>3.978640e+09</td>\n",
              "      <td>3.290940e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-04-27</th>\n",
              "      <td>3117.071916</td>\n",
              "      <td>3533.111601</td>\n",
              "      <td>2482.705836</td>\n",
              "      <td>3750550000</td>\n",
              "      <td>3928.897786</td>\n",
              "      <td>2804.523721</td>\n",
              "      <td>4420.336524</td>\n",
              "      <td>3157.972777</td>\n",
              "      <td>3169.792346</td>\n",
              "      <td>2268.912828</td>\n",
              "      <td>3.837030e+09</td>\n",
              "      <td>3.978640e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-04-28</th>\n",
              "      <td>3874.279091</td>\n",
              "      <td>4336.781289</td>\n",
              "      <td>3091.032770</td>\n",
              "      <td>4087800000</td>\n",
              "      <td>3117.071916</td>\n",
              "      <td>3928.897786</td>\n",
              "      <td>3533.111601</td>\n",
              "      <td>4420.336524</td>\n",
              "      <td>2482.705836</td>\n",
              "      <td>3169.792346</td>\n",
              "      <td>3.750550e+09</td>\n",
              "      <td>3.837030e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-01</th>\n",
              "      <td>2038.911417</td>\n",
              "      <td>2278.779337</td>\n",
              "      <td>1596.856390</td>\n",
              "      <td>3321370000</td>\n",
              "      <td>3874.279091</td>\n",
              "      <td>3117.071916</td>\n",
              "      <td>4336.781289</td>\n",
              "      <td>3533.111601</td>\n",
              "      <td>3091.032770</td>\n",
              "      <td>2482.705836</td>\n",
              "      <td>4.087800e+09</td>\n",
              "      <td>3.750550e+09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 12 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f339da27-b68c-48e1-82dd-8f8be00f3d84')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f339da27-b68c-48e1-82dd-8f8be00f3d84 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f339da27-b68c-48e1-82dd-8f8be00f3d84');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-154f2e9d-98f2-46c9-a6e4-46b63cd59ff9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-154f2e9d-98f2-46c9-a6e4-46b63cd59ff9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-154f2e9d-98f2-46c9-a6e4-46b63cd59ff9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #load traing labels\n",
        "\n",
        "Y_train_binary = Train_labels_df['Up']\n",
        "Y_train_binary\n",
        "\n",
        "Y_test_binary = Test_labels_df['Up']\n",
        "Y_test_binary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gugUarMvZ-Xy",
        "outputId": "e42e4a78-8059-4e41-c511-3b1be7480c89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "date\n",
              "2023-05-02    0\n",
              "2023-05-03    0\n",
              "2023-05-04    0\n",
              "2023-05-05    1\n",
              "2023-05-08    1\n",
              "2023-05-09    0\n",
              "2023-05-10    0\n",
              "2023-05-11    0\n",
              "2023-05-12    0\n",
              "2023-05-15    1\n",
              "2023-05-16    0\n",
              "2023-05-17    1\n",
              "2023-05-18    1\n",
              "2023-05-19    0\n",
              "2023-05-22    1\n",
              "2023-05-23    0\n",
              "2023-05-24    0\n",
              "2023-05-25    0\n",
              "2023-05-26    1\n",
              "2023-05-30    0\n",
              "2023-05-31    0\n",
              "2023-06-01    1\n",
              "2023-06-02    1\n",
              "2023-06-06    1\n",
              "2023-06-07    0\n",
              "2023-06-08    1\n",
              "2023-06-09    0\n",
              "2023-06-12    1\n",
              "2023-06-13    1\n",
              "2023-06-14    1\n",
              "2023-06-15    1\n",
              "2023-06-16    0\n",
              "2023-06-20    0\n",
              "2023-06-21    0\n",
              "2023-06-22    1\n",
              "2023-06-23    0\n",
              "2023-06-26    0\n",
              "2023-06-27    1\n",
              "2023-06-28    1\n",
              "2023-06-29    1\n",
              "2023-06-30    1\n",
              "Name: Up, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Training"
      ],
      "metadata": {
        "id": "Fr8ioMyjsKbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# training models\n",
        "\n",
        "# LSTM\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Gaussian Naive Bayes\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# SVM\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "\n",
        "# Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# XGBoost\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# KNeighborsClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Perceptron\n",
        "from sklearn.linear_model import Perceptron\n",
        "\n",
        "# Stochastic Gradient Descent (SGD)\n",
        "from sklearn.linear_model import SGDClassifier"
      ],
      "metadata": {
        "id": "pp4tc_fEt1xY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Deep learning models\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout, GlobalAveragePooling1D\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, Callback\n",
        "\n",
        "SEED = 1337\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "gXxW46IUcps3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gaussian Naive Bayes\n",
        "\n",
        "nb_clf = GaussianNB()\n",
        "nb_clf.fit(X_train_binary.values, Y_train_binary.values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "eNeDsn2I5TFm",
        "outputId": "859fe408-a6e7-4d8e-fcbc-22a538377480"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM\n",
        "# SVM doesn't support multiclass classification natively\n",
        "\n",
        "clf_svm = SVC(kernel='linear', C=1, max_iter=500)\n",
        "clf_svm.fit(X_train_binary.values, Y_train_binary.values)"
      ],
      "metadata": {
        "id": "W00a9LUoiCXh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "c702d028-3bb9-45bc-dc90-bf5be25ec0ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1, kernel='linear', max_iter=500)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1, kernel=&#x27;linear&#x27;, max_iter=500)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1, kernel=&#x27;linear&#x27;, max_iter=500)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest\n",
        "\n",
        "# the parameters meaning\n",
        "#  n_estimators 随机森林中树的个数，即学习器的个数。\n",
        "# n_jobs 并行使用的进程数，默认1个，如果设置为-1，该值为总的核数\n",
        "# max_depth 树的最大深度\n",
        "# random_state =42 just a common practice\n",
        "\n",
        "classifier_rf = RandomForestClassifier(random_state=42, n_jobs=-1, max_depth=15,\n",
        "                                       n_estimators=500)\n",
        "\n",
        "# Random Forest trained with NQ\n",
        "\n",
        "classifier_rf.fit(X_train_binary.values, Y_train_binary.values)"
      ],
      "metadata": {
        "id": "LpNckLbF1tlB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "e5557826-40ce-479f-c596-a96cb7e20e3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(max_depth=15, n_estimators=500, n_jobs=-1,\n",
              "                       random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=15, n_estimators=500, n_jobs=-1,\n",
              "                       random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=15, n_estimators=500, n_jobs=-1,\n",
              "                       random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest with XGB\n",
        "\n",
        "gbm_param_grid = {\n",
        "    'n_estimators': range(8, 300),\n",
        "    'max_depth': range(6, 20),\n",
        "    'learning_rate': [.4, .45, .5, .55, .6],\n",
        "    'colsample_bytree': [.6, .7, .8, .9, 1]\n",
        "}\n",
        "gbm = XGBClassifier(n_estimators=300)\n",
        "xgb_random = RandomizedSearchCV(param_distributions=gbm_param_grid,\n",
        "                                    estimator = gbm, scoring = \"accuracy\",\n",
        "                                    verbose = 1, n_iter = 50, cv = 4)\n",
        "# Random Forest with XGB trained with NQ\n",
        "\n",
        "xgb_random.fit(X_train_binary.values, Y_train_binary.values)"
      ],
      "metadata": {
        "id": "B8-BzNpb160q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "outputId": "cbc3e0cb-11af-49c4-bdb3-fdd85653b2d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 4 folds for each of 50 candidates, totalling 200 fits\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=4,\n",
              "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
              "                                           callbacks=None,\n",
              "                                           colsample_bylevel=None,\n",
              "                                           colsample_bynode=None,\n",
              "                                           colsample_bytree=None, device=None,\n",
              "                                           early_stopping_rounds=None,\n",
              "                                           enable_categorical=False,\n",
              "                                           eval_metric=None, feature_types=None,\n",
              "                                           gamma=None, grow_policy=None,\n",
              "                                           importance_type=None,\n",
              "                                           interaction_constraints=None,\n",
              "                                           learning_rate...\n",
              "                                           max_leaves=None,\n",
              "                                           min_child_weight=None, missing=nan,\n",
              "                                           monotone_constraints=None,\n",
              "                                           multi_strategy=None,\n",
              "                                           n_estimators=300, n_jobs=None,\n",
              "                                           num_parallel_tree=None,\n",
              "                                           random_state=None, ...),\n",
              "                   n_iter=50,\n",
              "                   param_distributions={'colsample_bytree': [0.6, 0.7, 0.8, 0.9,\n",
              "                                                             1],\n",
              "                                        'learning_rate': [0.4, 0.45, 0.5, 0.55,\n",
              "                                                          0.6],\n",
              "                                        'max_depth': range(6, 20),\n",
              "                                        'n_estimators': range(8, 300)},\n",
              "                   scoring='accuracy', verbose=1)"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=4,\n",
              "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
              "                                           callbacks=None,\n",
              "                                           colsample_bylevel=None,\n",
              "                                           colsample_bynode=None,\n",
              "                                           colsample_bytree=None, device=None,\n",
              "                                           early_stopping_rounds=None,\n",
              "                                           enable_categorical=False,\n",
              "                                           eval_metric=None, feature_types=None,\n",
              "                                           gamma=None, grow_policy=None,\n",
              "                                           importance_type=None,\n",
              "                                           interaction_constraints=None,\n",
              "                                           learning_rate...\n",
              "                                           max_leaves=None,\n",
              "                                           min_child_weight=None, missing=nan,\n",
              "                                           monotone_constraints=None,\n",
              "                                           multi_strategy=None,\n",
              "                                           n_estimators=300, n_jobs=None,\n",
              "                                           num_parallel_tree=None,\n",
              "                                           random_state=None, ...),\n",
              "                   n_iter=50,\n",
              "                   param_distributions={&#x27;colsample_bytree&#x27;: [0.6, 0.7, 0.8, 0.9,\n",
              "                                                             1],\n",
              "                                        &#x27;learning_rate&#x27;: [0.4, 0.45, 0.5, 0.55,\n",
              "                                                          0.6],\n",
              "                                        &#x27;max_depth&#x27;: range(6, 20),\n",
              "                                        &#x27;n_estimators&#x27;: range(8, 300)},\n",
              "                   scoring=&#x27;accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=4,\n",
              "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
              "                                           callbacks=None,\n",
              "                                           colsample_bylevel=None,\n",
              "                                           colsample_bynode=None,\n",
              "                                           colsample_bytree=None, device=None,\n",
              "                                           early_stopping_rounds=None,\n",
              "                                           enable_categorical=False,\n",
              "                                           eval_metric=None, feature_types=None,\n",
              "                                           gamma=None, grow_policy=None,\n",
              "                                           importance_type=None,\n",
              "                                           interaction_constraints=None,\n",
              "                                           learning_rate...\n",
              "                                           max_leaves=None,\n",
              "                                           min_child_weight=None, missing=nan,\n",
              "                                           monotone_constraints=None,\n",
              "                                           multi_strategy=None,\n",
              "                                           n_estimators=300, n_jobs=None,\n",
              "                                           num_parallel_tree=None,\n",
              "                                           random_state=None, ...),\n",
              "                   n_iter=50,\n",
              "                   param_distributions={&#x27;colsample_bytree&#x27;: [0.6, 0.7, 0.8, 0.9,\n",
              "                                                             1],\n",
              "                                        &#x27;learning_rate&#x27;: [0.4, 0.45, 0.5, 0.55,\n",
              "                                                          0.6],\n",
              "                                        &#x27;max_depth&#x27;: range(6, 20),\n",
              "                                        &#x27;n_estimators&#x27;: range(8, 300)},\n",
              "                   scoring=&#x27;accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
              "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
              "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# KNeighborsClassifier\n",
        "\n",
        "knn_clf = KNeighborsClassifier(n_neighbors = 10)\n",
        "knn_clf.fit(X_train_binary.values, Y_train_binary.values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "Z3NCWNSDvA8M",
        "outputId": "8f89efe3-df6a-43b9-fdc7-da1d52e0e2a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(n_neighbors=10)"
            ],
            "text/html": [
              "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=10)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perceptron\n",
        "\n",
        "per_clf = Perceptron(max_iter=10, tol=None)\n",
        "per_clf.fit(X_train_binary.values, Y_train_binary.values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "k0ezykWu77yC",
        "outputId": "37eaeca6-9c42-48c9-86a6-199d924301c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Perceptron(max_iter=10, tol=None)"
            ],
            "text/html": [
              "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Perceptron(max_iter=10, tol=None)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Perceptron</label><div class=\"sk-toggleable__content\"><pre>Perceptron(max_iter=10, tol=None)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stochastic Gradient Descent (SGD)\n",
        "\n",
        "sgd_clf = SGDClassifier(max_iter=10, tol=None)\n",
        "sgd_clf.fit(X_train_binary.values, Y_train_binary.values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "KwBd5l3v772n",
        "outputId": "b9cfb5e3-6e42-49a6-d074-d541a49bf9f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(max_iter=10, tol=None)"
            ],
            "text/html": [
              "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDClassifier(max_iter=10, tol=None)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(max_iter=10, tol=None)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Deep learning models\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_binary)\n",
        "\n",
        "# Convert target labels to one-hot encoded format\n",
        "label_encoder = LabelEncoder()\n",
        "Y_train_encoded = label_encoder.fit_transform(Y_train_binary)\n",
        "\n",
        "# Determine the number of unique classes\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "# Create a sequential model\n",
        "deep_clf = Sequential([\n",
        "    Dense(10, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Use sigmoid activation for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "deep_clf.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with a specified number of epochs\n",
        "deep_clf.fit(X_train_scaled, Y_train_encoded, epochs=1000, batch_size=30)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kb7HnX-Deojd",
        "outputId": "947bf4c2-34fe-4942-81b5-61df840d4f85"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "5/5 [==============================] - 1s 5ms/step - loss: 0.7996 - accuracy: 0.4867\n",
            "Epoch 2/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7819 - accuracy: 0.5000\n",
            "Epoch 3/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7709 - accuracy: 0.5067\n",
            "Epoch 4/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7622 - accuracy: 0.5067\n",
            "Epoch 5/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7542 - accuracy: 0.5200\n",
            "Epoch 6/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7479 - accuracy: 0.5200\n",
            "Epoch 7/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7417 - accuracy: 0.5133\n",
            "Epoch 8/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7362 - accuracy: 0.5200\n",
            "Epoch 9/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7310 - accuracy: 0.5267\n",
            "Epoch 10/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7258 - accuracy: 0.5200\n",
            "Epoch 11/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7215 - accuracy: 0.5267\n",
            "Epoch 12/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.7164 - accuracy: 0.5400\n",
            "Epoch 13/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7128 - accuracy: 0.5467\n",
            "Epoch 14/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7092 - accuracy: 0.5600\n",
            "Epoch 15/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7052 - accuracy: 0.5600\n",
            "Epoch 16/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7028 - accuracy: 0.5600\n",
            "Epoch 17/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6994 - accuracy: 0.5600\n",
            "Epoch 18/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6968 - accuracy: 0.5467\n",
            "Epoch 19/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6942 - accuracy: 0.5667\n",
            "Epoch 20/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6922 - accuracy: 0.5600\n",
            "Epoch 21/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6894 - accuracy: 0.6000\n",
            "Epoch 22/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6875 - accuracy: 0.5933\n",
            "Epoch 23/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6854 - accuracy: 0.6067\n",
            "Epoch 24/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6845 - accuracy: 0.6000\n",
            "Epoch 25/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6818 - accuracy: 0.6000\n",
            "Epoch 26/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6808 - accuracy: 0.5933\n",
            "Epoch 27/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6790 - accuracy: 0.5867\n",
            "Epoch 28/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6771 - accuracy: 0.5800\n",
            "Epoch 29/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6762 - accuracy: 0.5733\n",
            "Epoch 30/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6747 - accuracy: 0.5667\n",
            "Epoch 31/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6736 - accuracy: 0.5667\n",
            "Epoch 32/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.5733\n",
            "Epoch 33/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6714 - accuracy: 0.5733\n",
            "Epoch 34/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6710 - accuracy: 0.5533\n",
            "Epoch 35/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6693 - accuracy: 0.5533\n",
            "Epoch 36/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6688 - accuracy: 0.5600\n",
            "Epoch 37/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6673 - accuracy: 0.5600\n",
            "Epoch 38/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6675 - accuracy: 0.5667\n",
            "Epoch 39/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6662 - accuracy: 0.5800\n",
            "Epoch 40/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6654 - accuracy: 0.5667\n",
            "Epoch 41/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6642 - accuracy: 0.5733\n",
            "Epoch 42/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6634 - accuracy: 0.5733\n",
            "Epoch 43/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6630 - accuracy: 0.5667\n",
            "Epoch 44/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6625 - accuracy: 0.5667\n",
            "Epoch 45/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6611 - accuracy: 0.5667\n",
            "Epoch 46/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6603 - accuracy: 0.5800\n",
            "Epoch 47/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6598 - accuracy: 0.5867\n",
            "Epoch 48/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6590 - accuracy: 0.5800\n",
            "Epoch 49/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6583 - accuracy: 0.5867\n",
            "Epoch 50/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6585 - accuracy: 0.5733\n",
            "Epoch 51/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6568 - accuracy: 0.5933\n",
            "Epoch 52/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6567 - accuracy: 0.5800\n",
            "Epoch 53/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6560 - accuracy: 0.5800\n",
            "Epoch 54/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6552 - accuracy: 0.5933\n",
            "Epoch 55/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6545 - accuracy: 0.5933\n",
            "Epoch 56/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6536 - accuracy: 0.5867\n",
            "Epoch 57/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6535 - accuracy: 0.5933\n",
            "Epoch 58/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6533 - accuracy: 0.6000\n",
            "Epoch 59/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6522 - accuracy: 0.5867\n",
            "Epoch 60/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6515 - accuracy: 0.5933\n",
            "Epoch 61/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6512 - accuracy: 0.5867\n",
            "Epoch 62/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6507 - accuracy: 0.6000\n",
            "Epoch 63/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6509 - accuracy: 0.5800\n",
            "Epoch 64/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6494 - accuracy: 0.6000\n",
            "Epoch 65/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6490 - accuracy: 0.5867\n",
            "Epoch 66/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6487 - accuracy: 0.6000\n",
            "Epoch 67/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6479 - accuracy: 0.6133\n",
            "Epoch 68/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6475 - accuracy: 0.6067\n",
            "Epoch 69/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6475 - accuracy: 0.6200\n",
            "Epoch 70/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6477 - accuracy: 0.6200\n",
            "Epoch 71/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6457 - accuracy: 0.6267\n",
            "Epoch 72/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6457 - accuracy: 0.6200\n",
            "Epoch 73/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6452 - accuracy: 0.6267\n",
            "Epoch 74/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6451 - accuracy: 0.6200\n",
            "Epoch 75/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6443 - accuracy: 0.6200\n",
            "Epoch 76/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6438 - accuracy: 0.6267\n",
            "Epoch 77/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6435 - accuracy: 0.6200\n",
            "Epoch 78/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6431 - accuracy: 0.6200\n",
            "Epoch 79/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6429 - accuracy: 0.6200\n",
            "Epoch 80/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6426 - accuracy: 0.6067\n",
            "Epoch 81/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6418 - accuracy: 0.6267\n",
            "Epoch 82/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6411 - accuracy: 0.6200\n",
            "Epoch 83/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6411 - accuracy: 0.6200\n",
            "Epoch 84/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6403 - accuracy: 0.6133\n",
            "Epoch 85/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6397 - accuracy: 0.6267\n",
            "Epoch 86/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6398 - accuracy: 0.6200\n",
            "Epoch 87/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6393 - accuracy: 0.6267\n",
            "Epoch 88/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6391 - accuracy: 0.6267\n",
            "Epoch 89/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6387 - accuracy: 0.6267\n",
            "Epoch 90/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6382 - accuracy: 0.6200\n",
            "Epoch 91/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6375 - accuracy: 0.6267\n",
            "Epoch 92/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6375 - accuracy: 0.6267\n",
            "Epoch 93/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6374 - accuracy: 0.6200\n",
            "Epoch 94/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6362 - accuracy: 0.6200\n",
            "Epoch 95/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6368 - accuracy: 0.6267\n",
            "Epoch 96/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6363 - accuracy: 0.6133\n",
            "Epoch 97/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6356 - accuracy: 0.6200\n",
            "Epoch 98/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6359 - accuracy: 0.6200\n",
            "Epoch 99/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6357 - accuracy: 0.6200\n",
            "Epoch 100/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6347 - accuracy: 0.6200\n",
            "Epoch 101/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6344 - accuracy: 0.6133\n",
            "Epoch 102/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6341 - accuracy: 0.6267\n",
            "Epoch 103/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6338 - accuracy: 0.6133\n",
            "Epoch 104/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6333 - accuracy: 0.6200\n",
            "Epoch 105/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.6267\n",
            "Epoch 106/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6333 - accuracy: 0.6200\n",
            "Epoch 107/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.6267\n",
            "Epoch 108/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.6333\n",
            "Epoch 109/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.6267\n",
            "Epoch 110/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6319 - accuracy: 0.6400\n",
            "Epoch 111/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6319 - accuracy: 0.6267\n",
            "Epoch 112/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6313 - accuracy: 0.6333\n",
            "Epoch 113/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6311 - accuracy: 0.6400\n",
            "Epoch 114/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6310 - accuracy: 0.6267\n",
            "Epoch 115/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6305 - accuracy: 0.6400\n",
            "Epoch 116/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6300 - accuracy: 0.6333\n",
            "Epoch 117/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6298 - accuracy: 0.6467\n",
            "Epoch 118/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6296 - accuracy: 0.6467\n",
            "Epoch 119/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6294 - accuracy: 0.6467\n",
            "Epoch 120/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6295 - accuracy: 0.6467\n",
            "Epoch 121/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6285 - accuracy: 0.6400\n",
            "Epoch 122/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6292 - accuracy: 0.6333\n",
            "Epoch 123/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6283 - accuracy: 0.6400\n",
            "Epoch 124/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6282 - accuracy: 0.6333\n",
            "Epoch 125/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6281 - accuracy: 0.6400\n",
            "Epoch 126/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6278 - accuracy: 0.6400\n",
            "Epoch 127/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6272 - accuracy: 0.6400\n",
            "Epoch 128/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6272 - accuracy: 0.6400\n",
            "Epoch 129/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6273 - accuracy: 0.6467\n",
            "Epoch 130/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.6269 - accuracy: 0.6533\n",
            "Epoch 131/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.6267 - accuracy: 0.6400\n",
            "Epoch 132/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6259 - accuracy: 0.6400\n",
            "Epoch 133/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6260 - accuracy: 0.6400\n",
            "Epoch 134/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6261 - accuracy: 0.6333\n",
            "Epoch 135/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6257 - accuracy: 0.6533\n",
            "Epoch 136/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6255 - accuracy: 0.6533\n",
            "Epoch 137/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6253 - accuracy: 0.6533\n",
            "Epoch 138/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6252 - accuracy: 0.6533\n",
            "Epoch 139/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.6251 - accuracy: 0.6533\n",
            "Epoch 140/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6248 - accuracy: 0.6533\n",
            "Epoch 141/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6241 - accuracy: 0.6533\n",
            "Epoch 142/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6249 - accuracy: 0.6467\n",
            "Epoch 143/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6236 - accuracy: 0.6533\n",
            "Epoch 144/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6239 - accuracy: 0.6533\n",
            "Epoch 145/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6238 - accuracy: 0.6533\n",
            "Epoch 146/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6236 - accuracy: 0.6533\n",
            "Epoch 147/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6236 - accuracy: 0.6467\n",
            "Epoch 148/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6231 - accuracy: 0.6467\n",
            "Epoch 149/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6232 - accuracy: 0.6467\n",
            "Epoch 150/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6228 - accuracy: 0.6533\n",
            "Epoch 151/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6227 - accuracy: 0.6467\n",
            "Epoch 152/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6228 - accuracy: 0.6467\n",
            "Epoch 153/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6218 - accuracy: 0.6533\n",
            "Epoch 154/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6228 - accuracy: 0.6467\n",
            "Epoch 155/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6216 - accuracy: 0.6467\n",
            "Epoch 156/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6217 - accuracy: 0.6467\n",
            "Epoch 157/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6217 - accuracy: 0.6467\n",
            "Epoch 158/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6217 - accuracy: 0.6467\n",
            "Epoch 159/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6210 - accuracy: 0.6467\n",
            "Epoch 160/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6204 - accuracy: 0.6467\n",
            "Epoch 161/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6217 - accuracy: 0.6467\n",
            "Epoch 162/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6204 - accuracy: 0.6467\n",
            "Epoch 163/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6205 - accuracy: 0.6467\n",
            "Epoch 164/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6205 - accuracy: 0.6467\n",
            "Epoch 165/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6201 - accuracy: 0.6467\n",
            "Epoch 166/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6201 - accuracy: 0.6533\n",
            "Epoch 167/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6202 - accuracy: 0.6600\n",
            "Epoch 168/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6192 - accuracy: 0.6467\n",
            "Epoch 169/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6194 - accuracy: 0.6533\n",
            "Epoch 170/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6196 - accuracy: 0.6600\n",
            "Epoch 171/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6195 - accuracy: 0.6467\n",
            "Epoch 172/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6194 - accuracy: 0.6467\n",
            "Epoch 173/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6192 - accuracy: 0.6533\n",
            "Epoch 174/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6185 - accuracy: 0.6600\n",
            "Epoch 175/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6187 - accuracy: 0.6533\n",
            "Epoch 176/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6186 - accuracy: 0.6533\n",
            "Epoch 177/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6182 - accuracy: 0.6533\n",
            "Epoch 178/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6179 - accuracy: 0.6533\n",
            "Epoch 179/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6182 - accuracy: 0.6533\n",
            "Epoch 180/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6183 - accuracy: 0.6533\n",
            "Epoch 181/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6177 - accuracy: 0.6533\n",
            "Epoch 182/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6171 - accuracy: 0.6533\n",
            "Epoch 183/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6176 - accuracy: 0.6533\n",
            "Epoch 184/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6170 - accuracy: 0.6600\n",
            "Epoch 185/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6174 - accuracy: 0.6533\n",
            "Epoch 186/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6167 - accuracy: 0.6533\n",
            "Epoch 187/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6171 - accuracy: 0.6600\n",
            "Epoch 188/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6174 - accuracy: 0.6533\n",
            "Epoch 189/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6160 - accuracy: 0.6600\n",
            "Epoch 190/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6164 - accuracy: 0.6600\n",
            "Epoch 191/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6161 - accuracy: 0.6533\n",
            "Epoch 192/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6160 - accuracy: 0.6533\n",
            "Epoch 193/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6157 - accuracy: 0.6600\n",
            "Epoch 194/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6159 - accuracy: 0.6600\n",
            "Epoch 195/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6156 - accuracy: 0.6600\n",
            "Epoch 196/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6150 - accuracy: 0.6533\n",
            "Epoch 197/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6150 - accuracy: 0.6533\n",
            "Epoch 198/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6153 - accuracy: 0.6600\n",
            "Epoch 199/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6150 - accuracy: 0.6600\n",
            "Epoch 200/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6149 - accuracy: 0.6600\n",
            "Epoch 201/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6145 - accuracy: 0.6533\n",
            "Epoch 202/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6142 - accuracy: 0.6600\n",
            "Epoch 203/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6138 - accuracy: 0.6533\n",
            "Epoch 204/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6146 - accuracy: 0.6600\n",
            "Epoch 205/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6133 - accuracy: 0.6600\n",
            "Epoch 206/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6138 - accuracy: 0.6600\n",
            "Epoch 207/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6140 - accuracy: 0.6600\n",
            "Epoch 208/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6138 - accuracy: 0.6600\n",
            "Epoch 209/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6126 - accuracy: 0.6600\n",
            "Epoch 210/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6129 - accuracy: 0.6600\n",
            "Epoch 211/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6124 - accuracy: 0.6600\n",
            "Epoch 212/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6126 - accuracy: 0.6600\n",
            "Epoch 213/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6125 - accuracy: 0.6600\n",
            "Epoch 214/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6118 - accuracy: 0.6600\n",
            "Epoch 215/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6124 - accuracy: 0.6533\n",
            "Epoch 216/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6119 - accuracy: 0.6600\n",
            "Epoch 217/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6116 - accuracy: 0.6600\n",
            "Epoch 218/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6115 - accuracy: 0.6600\n",
            "Epoch 219/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6114 - accuracy: 0.6600\n",
            "Epoch 220/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6110 - accuracy: 0.6600\n",
            "Epoch 221/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6106 - accuracy: 0.6600\n",
            "Epoch 222/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6108 - accuracy: 0.6533\n",
            "Epoch 223/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6109 - accuracy: 0.6600\n",
            "Epoch 224/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6104 - accuracy: 0.6600\n",
            "Epoch 225/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6097 - accuracy: 0.6600\n",
            "Epoch 226/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6101 - accuracy: 0.6600\n",
            "Epoch 227/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6096 - accuracy: 0.6600\n",
            "Epoch 228/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6102 - accuracy: 0.6600\n",
            "Epoch 229/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6092 - accuracy: 0.6600\n",
            "Epoch 230/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6097 - accuracy: 0.6600\n",
            "Epoch 231/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6088 - accuracy: 0.6600\n",
            "Epoch 232/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6090 - accuracy: 0.6533\n",
            "Epoch 233/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6088 - accuracy: 0.6600\n",
            "Epoch 234/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6083 - accuracy: 0.6600\n",
            "Epoch 235/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6086 - accuracy: 0.6600\n",
            "Epoch 236/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6082 - accuracy: 0.6600\n",
            "Epoch 237/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6079 - accuracy: 0.6533\n",
            "Epoch 238/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6089 - accuracy: 0.6600\n",
            "Epoch 239/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6085 - accuracy: 0.6533\n",
            "Epoch 240/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6077 - accuracy: 0.6600\n",
            "Epoch 241/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6075 - accuracy: 0.6600\n",
            "Epoch 242/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6076 - accuracy: 0.6533\n",
            "Epoch 243/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6077 - accuracy: 0.6600\n",
            "Epoch 244/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6064 - accuracy: 0.6600\n",
            "Epoch 245/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6064 - accuracy: 0.6600\n",
            "Epoch 246/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6063 - accuracy: 0.6600\n",
            "Epoch 247/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6063 - accuracy: 0.6600\n",
            "Epoch 248/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6062 - accuracy: 0.6667\n",
            "Epoch 249/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6065 - accuracy: 0.6533\n",
            "Epoch 250/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6055 - accuracy: 0.6667\n",
            "Epoch 251/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6053 - accuracy: 0.6667\n",
            "Epoch 252/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6049 - accuracy: 0.6667\n",
            "Epoch 253/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6051 - accuracy: 0.6667\n",
            "Epoch 254/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6055 - accuracy: 0.6600\n",
            "Epoch 255/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6055 - accuracy: 0.6600\n",
            "Epoch 256/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6048 - accuracy: 0.6667\n",
            "Epoch 257/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6049 - accuracy: 0.6600\n",
            "Epoch 258/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6045 - accuracy: 0.6667\n",
            "Epoch 259/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6049 - accuracy: 0.6733\n",
            "Epoch 260/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6040 - accuracy: 0.6667\n",
            "Epoch 261/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6038 - accuracy: 0.6667\n",
            "Epoch 262/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6040 - accuracy: 0.6733\n",
            "Epoch 263/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6035 - accuracy: 0.6667\n",
            "Epoch 264/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6039 - accuracy: 0.6733\n",
            "Epoch 265/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6030 - accuracy: 0.6733\n",
            "Epoch 266/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6028 - accuracy: 0.6733\n",
            "Epoch 267/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6031 - accuracy: 0.6667\n",
            "Epoch 268/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6027 - accuracy: 0.6667\n",
            "Epoch 269/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6026 - accuracy: 0.6600\n",
            "Epoch 270/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6026 - accuracy: 0.6667\n",
            "Epoch 271/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6019 - accuracy: 0.6667\n",
            "Epoch 272/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6024 - accuracy: 0.6733\n",
            "Epoch 273/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6021 - accuracy: 0.6733\n",
            "Epoch 274/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6019 - accuracy: 0.6667\n",
            "Epoch 275/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6026 - accuracy: 0.6667\n",
            "Epoch 276/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6013 - accuracy: 0.6667\n",
            "Epoch 277/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6012 - accuracy: 0.6667\n",
            "Epoch 278/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6009 - accuracy: 0.6667\n",
            "Epoch 279/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6015 - accuracy: 0.6733\n",
            "Epoch 280/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6011 - accuracy: 0.6733\n",
            "Epoch 281/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6008 - accuracy: 0.6667\n",
            "Epoch 282/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6002 - accuracy: 0.6800\n",
            "Epoch 283/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6007 - accuracy: 0.6667\n",
            "Epoch 284/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6003 - accuracy: 0.6800\n",
            "Epoch 285/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6006 - accuracy: 0.6733\n",
            "Epoch 286/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6008 - accuracy: 0.6733\n",
            "Epoch 287/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5999 - accuracy: 0.6733\n",
            "Epoch 288/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5995 - accuracy: 0.6733\n",
            "Epoch 289/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5993 - accuracy: 0.6800\n",
            "Epoch 290/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5993 - accuracy: 0.6800\n",
            "Epoch 291/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5991 - accuracy: 0.6733\n",
            "Epoch 292/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5994 - accuracy: 0.6667\n",
            "Epoch 293/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5996 - accuracy: 0.6667\n",
            "Epoch 294/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5995 - accuracy: 0.6800\n",
            "Epoch 295/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5984 - accuracy: 0.6733\n",
            "Epoch 296/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5995 - accuracy: 0.6800\n",
            "Epoch 297/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5984 - accuracy: 0.6800\n",
            "Epoch 298/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5989 - accuracy: 0.6600\n",
            "Epoch 299/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5992 - accuracy: 0.6667\n",
            "Epoch 300/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5978 - accuracy: 0.6733\n",
            "Epoch 301/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5984 - accuracy: 0.6800\n",
            "Epoch 302/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5974 - accuracy: 0.6800\n",
            "Epoch 303/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5976 - accuracy: 0.6600\n",
            "Epoch 304/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5975 - accuracy: 0.6733\n",
            "Epoch 305/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5976 - accuracy: 0.6800\n",
            "Epoch 306/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5972 - accuracy: 0.6667\n",
            "Epoch 307/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5975 - accuracy: 0.6600\n",
            "Epoch 308/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5979 - accuracy: 0.6800\n",
            "Epoch 309/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5975 - accuracy: 0.6733\n",
            "Epoch 310/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5962 - accuracy: 0.6600\n",
            "Epoch 311/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5964 - accuracy: 0.6667\n",
            "Epoch 312/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5963 - accuracy: 0.6600\n",
            "Epoch 313/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5962 - accuracy: 0.6667\n",
            "Epoch 314/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5964 - accuracy: 0.6667\n",
            "Epoch 315/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5960 - accuracy: 0.6667\n",
            "Epoch 316/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5963 - accuracy: 0.6667\n",
            "Epoch 317/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5961 - accuracy: 0.6667\n",
            "Epoch 318/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5952 - accuracy: 0.6600\n",
            "Epoch 319/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5955 - accuracy: 0.6667\n",
            "Epoch 320/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5954 - accuracy: 0.6600\n",
            "Epoch 321/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5952 - accuracy: 0.6600\n",
            "Epoch 322/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5952 - accuracy: 0.6667\n",
            "Epoch 323/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5949 - accuracy: 0.6600\n",
            "Epoch 324/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5948 - accuracy: 0.6600\n",
            "Epoch 325/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5947 - accuracy: 0.6600\n",
            "Epoch 326/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5952 - accuracy: 0.6667\n",
            "Epoch 327/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5949 - accuracy: 0.6667\n",
            "Epoch 328/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5944 - accuracy: 0.6600\n",
            "Epoch 329/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5942 - accuracy: 0.6667\n",
            "Epoch 330/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5944 - accuracy: 0.6600\n",
            "Epoch 331/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5944 - accuracy: 0.6600\n",
            "Epoch 332/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5947 - accuracy: 0.6600\n",
            "Epoch 333/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5941 - accuracy: 0.6600\n",
            "Epoch 334/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5944 - accuracy: 0.6667\n",
            "Epoch 335/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5936 - accuracy: 0.6600\n",
            "Epoch 336/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5930 - accuracy: 0.6600\n",
            "Epoch 337/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5936 - accuracy: 0.6667\n",
            "Epoch 338/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5930 - accuracy: 0.6600\n",
            "Epoch 339/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5934 - accuracy: 0.6600\n",
            "Epoch 340/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5944 - accuracy: 0.6600\n",
            "Epoch 341/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5927 - accuracy: 0.6600\n",
            "Epoch 342/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5924 - accuracy: 0.6667\n",
            "Epoch 343/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5931 - accuracy: 0.6667\n",
            "Epoch 344/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5928 - accuracy: 0.6600\n",
            "Epoch 345/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5924 - accuracy: 0.6600\n",
            "Epoch 346/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5919 - accuracy: 0.6600\n",
            "Epoch 347/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5918 - accuracy: 0.6600\n",
            "Epoch 348/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5922 - accuracy: 0.6600\n",
            "Epoch 349/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5920 - accuracy: 0.6600\n",
            "Epoch 350/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5918 - accuracy: 0.6600\n",
            "Epoch 351/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5911 - accuracy: 0.6600\n",
            "Epoch 352/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5915 - accuracy: 0.6600\n",
            "Epoch 353/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5912 - accuracy: 0.6600\n",
            "Epoch 354/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5923 - accuracy: 0.6600\n",
            "Epoch 355/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5912 - accuracy: 0.6600\n",
            "Epoch 356/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5912 - accuracy: 0.6600\n",
            "Epoch 357/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5905 - accuracy: 0.6600\n",
            "Epoch 358/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5906 - accuracy: 0.6600\n",
            "Epoch 359/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5907 - accuracy: 0.6600\n",
            "Epoch 360/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5906 - accuracy: 0.6600\n",
            "Epoch 361/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5912 - accuracy: 0.6533\n",
            "Epoch 362/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5896 - accuracy: 0.6600\n",
            "Epoch 363/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5897 - accuracy: 0.6600\n",
            "Epoch 364/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5902 - accuracy: 0.6600\n",
            "Epoch 365/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5904 - accuracy: 0.6533\n",
            "Epoch 366/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5900 - accuracy: 0.6533\n",
            "Epoch 367/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5897 - accuracy: 0.6600\n",
            "Epoch 368/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5902 - accuracy: 0.6667\n",
            "Epoch 369/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5890 - accuracy: 0.6600\n",
            "Epoch 370/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5888 - accuracy: 0.6600\n",
            "Epoch 371/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5890 - accuracy: 0.6600\n",
            "Epoch 372/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5889 - accuracy: 0.6533\n",
            "Epoch 373/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5884 - accuracy: 0.6533\n",
            "Epoch 374/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5883 - accuracy: 0.6533\n",
            "Epoch 375/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5886 - accuracy: 0.6533\n",
            "Epoch 376/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5885 - accuracy: 0.6533\n",
            "Epoch 377/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5879 - accuracy: 0.6533\n",
            "Epoch 378/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5884 - accuracy: 0.6533\n",
            "Epoch 379/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5879 - accuracy: 0.6600\n",
            "Epoch 380/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5880 - accuracy: 0.6533\n",
            "Epoch 381/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5882 - accuracy: 0.6533\n",
            "Epoch 382/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5872 - accuracy: 0.6600\n",
            "Epoch 383/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5874 - accuracy: 0.6600\n",
            "Epoch 384/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5884 - accuracy: 0.6667\n",
            "Epoch 385/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5874 - accuracy: 0.6600\n",
            "Epoch 386/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5874 - accuracy: 0.6600\n",
            "Epoch 387/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5874 - accuracy: 0.6600\n",
            "Epoch 388/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5866 - accuracy: 0.6600\n",
            "Epoch 389/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5868 - accuracy: 0.6533\n",
            "Epoch 390/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5873 - accuracy: 0.6533\n",
            "Epoch 391/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5873 - accuracy: 0.6467\n",
            "Epoch 392/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5860 - accuracy: 0.6667\n",
            "Epoch 393/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5866 - accuracy: 0.6667\n",
            "Epoch 394/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5864 - accuracy: 0.6600\n",
            "Epoch 395/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5862 - accuracy: 0.6600\n",
            "Epoch 396/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5862 - accuracy: 0.6600\n",
            "Epoch 397/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5857 - accuracy: 0.6600\n",
            "Epoch 398/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5859 - accuracy: 0.6533\n",
            "Epoch 399/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5861 - accuracy: 0.6600\n",
            "Epoch 400/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5856 - accuracy: 0.6467\n",
            "Epoch 401/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5853 - accuracy: 0.6533\n",
            "Epoch 402/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5858 - accuracy: 0.6600\n",
            "Epoch 403/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5849 - accuracy: 0.6467\n",
            "Epoch 404/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5853 - accuracy: 0.6600\n",
            "Epoch 405/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5852 - accuracy: 0.6600\n",
            "Epoch 406/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5843 - accuracy: 0.6667\n",
            "Epoch 407/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5856 - accuracy: 0.6600\n",
            "Epoch 408/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5847 - accuracy: 0.6667\n",
            "Epoch 409/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5840 - accuracy: 0.6600\n",
            "Epoch 410/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5839 - accuracy: 0.6600\n",
            "Epoch 411/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5843 - accuracy: 0.6600\n",
            "Epoch 412/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5838 - accuracy: 0.6600\n",
            "Epoch 413/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5841 - accuracy: 0.6600\n",
            "Epoch 414/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5839 - accuracy: 0.6667\n",
            "Epoch 415/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5836 - accuracy: 0.6600\n",
            "Epoch 416/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5832 - accuracy: 0.6533\n",
            "Epoch 417/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5847 - accuracy: 0.6533\n",
            "Epoch 418/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5836 - accuracy: 0.6600\n",
            "Epoch 419/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5834 - accuracy: 0.6600\n",
            "Epoch 420/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5832 - accuracy: 0.6600\n",
            "Epoch 421/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5834 - accuracy: 0.6600\n",
            "Epoch 422/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5832 - accuracy: 0.6600\n",
            "Epoch 423/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5836 - accuracy: 0.6600\n",
            "Epoch 424/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5831 - accuracy: 0.6667\n",
            "Epoch 425/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5821 - accuracy: 0.6600\n",
            "Epoch 426/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5826 - accuracy: 0.6600\n",
            "Epoch 427/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5823 - accuracy: 0.6667\n",
            "Epoch 428/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5824 - accuracy: 0.6600\n",
            "Epoch 429/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5822 - accuracy: 0.6667\n",
            "Epoch 430/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5819 - accuracy: 0.6600\n",
            "Epoch 431/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5825 - accuracy: 0.6600\n",
            "Epoch 432/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5824 - accuracy: 0.6733\n",
            "Epoch 433/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5824 - accuracy: 0.6733\n",
            "Epoch 434/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5820 - accuracy: 0.6733\n",
            "Epoch 435/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5815 - accuracy: 0.6667\n",
            "Epoch 436/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5816 - accuracy: 0.6667\n",
            "Epoch 437/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5820 - accuracy: 0.6400\n",
            "Epoch 438/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5808 - accuracy: 0.6667\n",
            "Epoch 439/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5805 - accuracy: 0.6733\n",
            "Epoch 440/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5807 - accuracy: 0.6667\n",
            "Epoch 441/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5808 - accuracy: 0.6600\n",
            "Epoch 442/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5816 - accuracy: 0.6667\n",
            "Epoch 443/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5802 - accuracy: 0.6667\n",
            "Epoch 444/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5805 - accuracy: 0.6600\n",
            "Epoch 445/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5802 - accuracy: 0.6667\n",
            "Epoch 446/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5808 - accuracy: 0.6600\n",
            "Epoch 447/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5807 - accuracy: 0.6600\n",
            "Epoch 448/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5798 - accuracy: 0.6600\n",
            "Epoch 449/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5796 - accuracy: 0.6800\n",
            "Epoch 450/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5795 - accuracy: 0.6667\n",
            "Epoch 451/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5798 - accuracy: 0.6600\n",
            "Epoch 452/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5789 - accuracy: 0.6667\n",
            "Epoch 453/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5791 - accuracy: 0.6667\n",
            "Epoch 454/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5791 - accuracy: 0.6600\n",
            "Epoch 455/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5796 - accuracy: 0.6733\n",
            "Epoch 456/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5788 - accuracy: 0.6667\n",
            "Epoch 457/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5786 - accuracy: 0.6733\n",
            "Epoch 458/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5800 - accuracy: 0.6667\n",
            "Epoch 459/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5786 - accuracy: 0.6667\n",
            "Epoch 460/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5785 - accuracy: 0.6733\n",
            "Epoch 461/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5789 - accuracy: 0.6733\n",
            "Epoch 462/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5788 - accuracy: 0.6733\n",
            "Epoch 463/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5774 - accuracy: 0.6733\n",
            "Epoch 464/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5788 - accuracy: 0.6667\n",
            "Epoch 465/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5781 - accuracy: 0.6733\n",
            "Epoch 466/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5775 - accuracy: 0.6800\n",
            "Epoch 467/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5776 - accuracy: 0.6733\n",
            "Epoch 468/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5781 - accuracy: 0.6800\n",
            "Epoch 469/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5774 - accuracy: 0.6733\n",
            "Epoch 470/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5771 - accuracy: 0.6733\n",
            "Epoch 471/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5775 - accuracy: 0.6800\n",
            "Epoch 472/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5772 - accuracy: 0.6800\n",
            "Epoch 473/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5772 - accuracy: 0.6800\n",
            "Epoch 474/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5768 - accuracy: 0.6800\n",
            "Epoch 475/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5767 - accuracy: 0.6800\n",
            "Epoch 476/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5767 - accuracy: 0.6867\n",
            "Epoch 477/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5766 - accuracy: 0.6733\n",
            "Epoch 478/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5763 - accuracy: 0.6800\n",
            "Epoch 479/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5766 - accuracy: 0.6800\n",
            "Epoch 480/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5770 - accuracy: 0.6800\n",
            "Epoch 481/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5763 - accuracy: 0.6800\n",
            "Epoch 482/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5759 - accuracy: 0.6800\n",
            "Epoch 483/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5754 - accuracy: 0.6800\n",
            "Epoch 484/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5760 - accuracy: 0.6800\n",
            "Epoch 485/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5756 - accuracy: 0.6800\n",
            "Epoch 486/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5754 - accuracy: 0.6800\n",
            "Epoch 487/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5758 - accuracy: 0.6800\n",
            "Epoch 488/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5750 - accuracy: 0.6800\n",
            "Epoch 489/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5750 - accuracy: 0.6800\n",
            "Epoch 490/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5746 - accuracy: 0.6800\n",
            "Epoch 491/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5743 - accuracy: 0.6800\n",
            "Epoch 492/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5746 - accuracy: 0.6800\n",
            "Epoch 493/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5751 - accuracy: 0.6733\n",
            "Epoch 494/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5744 - accuracy: 0.6800\n",
            "Epoch 495/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5740 - accuracy: 0.6800\n",
            "Epoch 496/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5747 - accuracy: 0.6800\n",
            "Epoch 497/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5740 - accuracy: 0.6800\n",
            "Epoch 498/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5732 - accuracy: 0.6867\n",
            "Epoch 499/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5738 - accuracy: 0.6733\n",
            "Epoch 500/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5733 - accuracy: 0.6800\n",
            "Epoch 501/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5729 - accuracy: 0.6800\n",
            "Epoch 502/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5732 - accuracy: 0.6800\n",
            "Epoch 503/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5736 - accuracy: 0.6800\n",
            "Epoch 504/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5724 - accuracy: 0.6800\n",
            "Epoch 505/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5728 - accuracy: 0.6800\n",
            "Epoch 506/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5727 - accuracy: 0.6800\n",
            "Epoch 507/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5722 - accuracy: 0.6800\n",
            "Epoch 508/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5729 - accuracy: 0.6800\n",
            "Epoch 509/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5725 - accuracy: 0.6800\n",
            "Epoch 510/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5721 - accuracy: 0.6800\n",
            "Epoch 511/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5714 - accuracy: 0.6800\n",
            "Epoch 512/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5715 - accuracy: 0.6800\n",
            "Epoch 513/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5716 - accuracy: 0.6867\n",
            "Epoch 514/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5711 - accuracy: 0.6800\n",
            "Epoch 515/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5713 - accuracy: 0.6800\n",
            "Epoch 516/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5711 - accuracy: 0.6800\n",
            "Epoch 517/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5708 - accuracy: 0.6867\n",
            "Epoch 518/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5712 - accuracy: 0.6867\n",
            "Epoch 519/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5701 - accuracy: 0.6867\n",
            "Epoch 520/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5712 - accuracy: 0.6800\n",
            "Epoch 521/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5705 - accuracy: 0.6733\n",
            "Epoch 522/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5703 - accuracy: 0.6933\n",
            "Epoch 523/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5708 - accuracy: 0.6800\n",
            "Epoch 524/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5700 - accuracy: 0.6800\n",
            "Epoch 525/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5699 - accuracy: 0.6867\n",
            "Epoch 526/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5703 - accuracy: 0.6800\n",
            "Epoch 527/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5688 - accuracy: 0.6867\n",
            "Epoch 528/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5693 - accuracy: 0.6800\n",
            "Epoch 529/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5689 - accuracy: 0.6933\n",
            "Epoch 530/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5693 - accuracy: 0.6933\n",
            "Epoch 531/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5696 - accuracy: 0.6933\n",
            "Epoch 532/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5682 - accuracy: 0.6933\n",
            "Epoch 533/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5684 - accuracy: 0.6933\n",
            "Epoch 534/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5687 - accuracy: 0.6933\n",
            "Epoch 535/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5695 - accuracy: 0.6867\n",
            "Epoch 536/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5686 - accuracy: 0.6867\n",
            "Epoch 537/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5680 - accuracy: 0.6867\n",
            "Epoch 538/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5685 - accuracy: 0.6867\n",
            "Epoch 539/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5675 - accuracy: 0.6933\n",
            "Epoch 540/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5680 - accuracy: 0.6867\n",
            "Epoch 541/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5672 - accuracy: 0.6933\n",
            "Epoch 542/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5674 - accuracy: 0.6867\n",
            "Epoch 543/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5670 - accuracy: 0.6933\n",
            "Epoch 544/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5673 - accuracy: 0.6933\n",
            "Epoch 545/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5674 - accuracy: 0.6933\n",
            "Epoch 546/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5666 - accuracy: 0.6933\n",
            "Epoch 547/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5661 - accuracy: 0.6867\n",
            "Epoch 548/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5657 - accuracy: 0.6800\n",
            "Epoch 549/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5656 - accuracy: 0.6933\n",
            "Epoch 550/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5668 - accuracy: 0.6933\n",
            "Epoch 551/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5662 - accuracy: 0.6800\n",
            "Epoch 552/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5665 - accuracy: 0.7000\n",
            "Epoch 553/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5654 - accuracy: 0.6867\n",
            "Epoch 554/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5653 - accuracy: 0.6800\n",
            "Epoch 555/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5647 - accuracy: 0.6867\n",
            "Epoch 556/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5648 - accuracy: 0.6933\n",
            "Epoch 557/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5655 - accuracy: 0.6867\n",
            "Epoch 558/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5650 - accuracy: 0.6867\n",
            "Epoch 559/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5644 - accuracy: 0.6867\n",
            "Epoch 560/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5643 - accuracy: 0.6867\n",
            "Epoch 561/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5646 - accuracy: 0.6867\n",
            "Epoch 562/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5647 - accuracy: 0.6800\n",
            "Epoch 563/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5645 - accuracy: 0.6867\n",
            "Epoch 564/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5646 - accuracy: 0.6800\n",
            "Epoch 565/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5644 - accuracy: 0.6800\n",
            "Epoch 566/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5636 - accuracy: 0.6867\n",
            "Epoch 567/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5642 - accuracy: 0.6800\n",
            "Epoch 568/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5634 - accuracy: 0.6867\n",
            "Epoch 569/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5632 - accuracy: 0.6867\n",
            "Epoch 570/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5633 - accuracy: 0.6867\n",
            "Epoch 571/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5643 - accuracy: 0.6867\n",
            "Epoch 572/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5626 - accuracy: 0.6867\n",
            "Epoch 573/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5623 - accuracy: 0.6867\n",
            "Epoch 574/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5631 - accuracy: 0.6933\n",
            "Epoch 575/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5639 - accuracy: 0.6933\n",
            "Epoch 576/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5638 - accuracy: 0.6800\n",
            "Epoch 577/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5628 - accuracy: 0.6800\n",
            "Epoch 578/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5623 - accuracy: 0.6800\n",
            "Epoch 579/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5624 - accuracy: 0.6933\n",
            "Epoch 580/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5616 - accuracy: 0.6800\n",
            "Epoch 581/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5619 - accuracy: 0.6800\n",
            "Epoch 582/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5625 - accuracy: 0.6867\n",
            "Epoch 583/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5613 - accuracy: 0.6733\n",
            "Epoch 584/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5617 - accuracy: 0.6800\n",
            "Epoch 585/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5617 - accuracy: 0.6867\n",
            "Epoch 586/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5628 - accuracy: 0.6800\n",
            "Epoch 587/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5612 - accuracy: 0.6867\n",
            "Epoch 588/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5620 - accuracy: 0.6800\n",
            "Epoch 589/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5610 - accuracy: 0.6867\n",
            "Epoch 590/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5614 - accuracy: 0.6867\n",
            "Epoch 591/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5610 - accuracy: 0.6867\n",
            "Epoch 592/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5612 - accuracy: 0.6800\n",
            "Epoch 593/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5608 - accuracy: 0.6867\n",
            "Epoch 594/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5605 - accuracy: 0.6867\n",
            "Epoch 595/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5605 - accuracy: 0.6800\n",
            "Epoch 596/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5611 - accuracy: 0.6800\n",
            "Epoch 597/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5600 - accuracy: 0.6867\n",
            "Epoch 598/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5600 - accuracy: 0.6867\n",
            "Epoch 599/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5604 - accuracy: 0.6867\n",
            "Epoch 600/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5596 - accuracy: 0.6800\n",
            "Epoch 601/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5597 - accuracy: 0.6867\n",
            "Epoch 602/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5599 - accuracy: 0.6867\n",
            "Epoch 603/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5604 - accuracy: 0.6867\n",
            "Epoch 604/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5596 - accuracy: 0.6933\n",
            "Epoch 605/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5594 - accuracy: 0.6867\n",
            "Epoch 606/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5591 - accuracy: 0.6867\n",
            "Epoch 607/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5607 - accuracy: 0.6800\n",
            "Epoch 608/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5588 - accuracy: 0.6867\n",
            "Epoch 609/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5586 - accuracy: 0.6800\n",
            "Epoch 610/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5606 - accuracy: 0.6867\n",
            "Epoch 611/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5598 - accuracy: 0.6800\n",
            "Epoch 612/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5579 - accuracy: 0.6800\n",
            "Epoch 613/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5578 - accuracy: 0.6867\n",
            "Epoch 614/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5592 - accuracy: 0.6867\n",
            "Epoch 615/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5581 - accuracy: 0.6800\n",
            "Epoch 616/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5576 - accuracy: 0.6800\n",
            "Epoch 617/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5580 - accuracy: 0.6867\n",
            "Epoch 618/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5577 - accuracy: 0.6867\n",
            "Epoch 619/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5578 - accuracy: 0.6867\n",
            "Epoch 620/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5579 - accuracy: 0.6867\n",
            "Epoch 621/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5569 - accuracy: 0.6800\n",
            "Epoch 622/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5570 - accuracy: 0.6933\n",
            "Epoch 623/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5570 - accuracy: 0.6867\n",
            "Epoch 624/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5572 - accuracy: 0.6867\n",
            "Epoch 625/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5572 - accuracy: 0.6867\n",
            "Epoch 626/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5573 - accuracy: 0.6933\n",
            "Epoch 627/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5567 - accuracy: 0.6867\n",
            "Epoch 628/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5574 - accuracy: 0.6933\n",
            "Epoch 629/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5563 - accuracy: 0.6933\n",
            "Epoch 630/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5561 - accuracy: 0.6800\n",
            "Epoch 631/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5557 - accuracy: 0.6933\n",
            "Epoch 632/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5555 - accuracy: 0.6867\n",
            "Epoch 633/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5570 - accuracy: 0.6867\n",
            "Epoch 634/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5557 - accuracy: 0.6933\n",
            "Epoch 635/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5554 - accuracy: 0.7000\n",
            "Epoch 636/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5562 - accuracy: 0.6933\n",
            "Epoch 637/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5547 - accuracy: 0.6933\n",
            "Epoch 638/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5570 - accuracy: 0.6800\n",
            "Epoch 639/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5548 - accuracy: 0.6933\n",
            "Epoch 640/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5557 - accuracy: 0.6867\n",
            "Epoch 641/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5555 - accuracy: 0.6867\n",
            "Epoch 642/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5546 - accuracy: 0.6933\n",
            "Epoch 643/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5549 - accuracy: 0.6933\n",
            "Epoch 644/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5550 - accuracy: 0.7000\n",
            "Epoch 645/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5548 - accuracy: 0.7000\n",
            "Epoch 646/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5552 - accuracy: 0.6933\n",
            "Epoch 647/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5542 - accuracy: 0.6933\n",
            "Epoch 648/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5544 - accuracy: 0.7000\n",
            "Epoch 649/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5551 - accuracy: 0.6933\n",
            "Epoch 650/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5537 - accuracy: 0.6933\n",
            "Epoch 651/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5547 - accuracy: 0.6933\n",
            "Epoch 652/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5548 - accuracy: 0.7000\n",
            "Epoch 653/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5534 - accuracy: 0.6933\n",
            "Epoch 654/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5532 - accuracy: 0.7000\n",
            "Epoch 655/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5540 - accuracy: 0.6933\n",
            "Epoch 656/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5531 - accuracy: 0.7000\n",
            "Epoch 657/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5533 - accuracy: 0.7000\n",
            "Epoch 658/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5539 - accuracy: 0.7000\n",
            "Epoch 659/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5535 - accuracy: 0.7067\n",
            "Epoch 660/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5528 - accuracy: 0.7000\n",
            "Epoch 661/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5537 - accuracy: 0.7000\n",
            "Epoch 662/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5527 - accuracy: 0.6933\n",
            "Epoch 663/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5540 - accuracy: 0.6933\n",
            "Epoch 664/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5531 - accuracy: 0.7000\n",
            "Epoch 665/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5526 - accuracy: 0.7000\n",
            "Epoch 666/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5533 - accuracy: 0.6933\n",
            "Epoch 667/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5532 - accuracy: 0.7000\n",
            "Epoch 668/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5526 - accuracy: 0.6933\n",
            "Epoch 669/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5521 - accuracy: 0.6933\n",
            "Epoch 670/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5523 - accuracy: 0.7067\n",
            "Epoch 671/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5522 - accuracy: 0.7000\n",
            "Epoch 672/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5517 - accuracy: 0.7000\n",
            "Epoch 673/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5520 - accuracy: 0.6933\n",
            "Epoch 674/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5522 - accuracy: 0.6933\n",
            "Epoch 675/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5528 - accuracy: 0.7067\n",
            "Epoch 676/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5513 - accuracy: 0.7000\n",
            "Epoch 677/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5518 - accuracy: 0.7000\n",
            "Epoch 678/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5514 - accuracy: 0.7000\n",
            "Epoch 679/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5512 - accuracy: 0.7067\n",
            "Epoch 680/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5513 - accuracy: 0.7067\n",
            "Epoch 681/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5509 - accuracy: 0.7000\n",
            "Epoch 682/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5514 - accuracy: 0.7067\n",
            "Epoch 683/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5511 - accuracy: 0.7133\n",
            "Epoch 684/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5511 - accuracy: 0.7000\n",
            "Epoch 685/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5509 - accuracy: 0.7000\n",
            "Epoch 686/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5520 - accuracy: 0.7067\n",
            "Epoch 687/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5511 - accuracy: 0.7000\n",
            "Epoch 688/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5502 - accuracy: 0.7067\n",
            "Epoch 689/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5511 - accuracy: 0.7067\n",
            "Epoch 690/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5510 - accuracy: 0.6933\n",
            "Epoch 691/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5508 - accuracy: 0.7067\n",
            "Epoch 692/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5502 - accuracy: 0.7067\n",
            "Epoch 693/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5507 - accuracy: 0.7067\n",
            "Epoch 694/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5498 - accuracy: 0.7067\n",
            "Epoch 695/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5503 - accuracy: 0.7067\n",
            "Epoch 696/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5507 - accuracy: 0.7067\n",
            "Epoch 697/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5504 - accuracy: 0.7067\n",
            "Epoch 698/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5497 - accuracy: 0.7067\n",
            "Epoch 699/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5498 - accuracy: 0.7067\n",
            "Epoch 700/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5498 - accuracy: 0.7000\n",
            "Epoch 701/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5496 - accuracy: 0.7000\n",
            "Epoch 702/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5495 - accuracy: 0.7133\n",
            "Epoch 703/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5491 - accuracy: 0.7067\n",
            "Epoch 704/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5497 - accuracy: 0.7067\n",
            "Epoch 705/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5498 - accuracy: 0.6933\n",
            "Epoch 706/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5487 - accuracy: 0.7067\n",
            "Epoch 707/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5499 - accuracy: 0.7067\n",
            "Epoch 708/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5491 - accuracy: 0.7067\n",
            "Epoch 709/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5494 - accuracy: 0.7067\n",
            "Epoch 710/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5485 - accuracy: 0.7067\n",
            "Epoch 711/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5492 - accuracy: 0.7067\n",
            "Epoch 712/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5493 - accuracy: 0.7067\n",
            "Epoch 713/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5485 - accuracy: 0.7133\n",
            "Epoch 714/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5486 - accuracy: 0.7067\n",
            "Epoch 715/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5481 - accuracy: 0.7133\n",
            "Epoch 716/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5482 - accuracy: 0.7133\n",
            "Epoch 717/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5481 - accuracy: 0.7067\n",
            "Epoch 718/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5492 - accuracy: 0.7133\n",
            "Epoch 719/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5479 - accuracy: 0.7133\n",
            "Epoch 720/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5479 - accuracy: 0.7067\n",
            "Epoch 721/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5475 - accuracy: 0.7133\n",
            "Epoch 722/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5471 - accuracy: 0.7133\n",
            "Epoch 723/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5476 - accuracy: 0.7133\n",
            "Epoch 724/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5470 - accuracy: 0.7133\n",
            "Epoch 725/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5474 - accuracy: 0.7133\n",
            "Epoch 726/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5481 - accuracy: 0.7133\n",
            "Epoch 727/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5469 - accuracy: 0.7133\n",
            "Epoch 728/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5469 - accuracy: 0.7133\n",
            "Epoch 729/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5474 - accuracy: 0.7200\n",
            "Epoch 730/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5478 - accuracy: 0.7067\n",
            "Epoch 731/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5465 - accuracy: 0.7133\n",
            "Epoch 732/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5476 - accuracy: 0.7200\n",
            "Epoch 733/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5467 - accuracy: 0.7067\n",
            "Epoch 734/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5467 - accuracy: 0.7133\n",
            "Epoch 735/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5461 - accuracy: 0.7133\n",
            "Epoch 736/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5470 - accuracy: 0.7267\n",
            "Epoch 737/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5471 - accuracy: 0.7200\n",
            "Epoch 738/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5461 - accuracy: 0.7200\n",
            "Epoch 739/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5463 - accuracy: 0.7200\n",
            "Epoch 740/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5454 - accuracy: 0.7133\n",
            "Epoch 741/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5472 - accuracy: 0.7200\n",
            "Epoch 742/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5447 - accuracy: 0.7200\n",
            "Epoch 743/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5456 - accuracy: 0.7200\n",
            "Epoch 744/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5464 - accuracy: 0.7133\n",
            "Epoch 745/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5458 - accuracy: 0.7200\n",
            "Epoch 746/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5465 - accuracy: 0.7200\n",
            "Epoch 747/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5460 - accuracy: 0.7133\n",
            "Epoch 748/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5456 - accuracy: 0.7200\n",
            "Epoch 749/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5450 - accuracy: 0.7200\n",
            "Epoch 750/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5455 - accuracy: 0.7267\n",
            "Epoch 751/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5456 - accuracy: 0.7200\n",
            "Epoch 752/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5450 - accuracy: 0.7200\n",
            "Epoch 753/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5457 - accuracy: 0.7200\n",
            "Epoch 754/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5445 - accuracy: 0.7200\n",
            "Epoch 755/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5455 - accuracy: 0.7200\n",
            "Epoch 756/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5449 - accuracy: 0.7133\n",
            "Epoch 757/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5440 - accuracy: 0.7200\n",
            "Epoch 758/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5455 - accuracy: 0.7267\n",
            "Epoch 759/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5439 - accuracy: 0.7200\n",
            "Epoch 760/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5445 - accuracy: 0.7200\n",
            "Epoch 761/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5447 - accuracy: 0.7200\n",
            "Epoch 762/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5442 - accuracy: 0.7200\n",
            "Epoch 763/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5439 - accuracy: 0.7200\n",
            "Epoch 764/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5442 - accuracy: 0.7267\n",
            "Epoch 765/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5439 - accuracy: 0.7200\n",
            "Epoch 766/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5446 - accuracy: 0.7200\n",
            "Epoch 767/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5439 - accuracy: 0.7200\n",
            "Epoch 768/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5437 - accuracy: 0.7200\n",
            "Epoch 769/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5433 - accuracy: 0.7200\n",
            "Epoch 770/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5436 - accuracy: 0.7200\n",
            "Epoch 771/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5428 - accuracy: 0.7200\n",
            "Epoch 772/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5425 - accuracy: 0.7200\n",
            "Epoch 773/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5430 - accuracy: 0.7267\n",
            "Epoch 774/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5450 - accuracy: 0.7200\n",
            "Epoch 775/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5424 - accuracy: 0.7200\n",
            "Epoch 776/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5428 - accuracy: 0.7267\n",
            "Epoch 777/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5428 - accuracy: 0.7267\n",
            "Epoch 778/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5432 - accuracy: 0.7200\n",
            "Epoch 779/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5428 - accuracy: 0.7267\n",
            "Epoch 780/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5433 - accuracy: 0.7200\n",
            "Epoch 781/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5420 - accuracy: 0.7200\n",
            "Epoch 782/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5431 - accuracy: 0.7133\n",
            "Epoch 783/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5419 - accuracy: 0.7200\n",
            "Epoch 784/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5426 - accuracy: 0.7200\n",
            "Epoch 785/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5415 - accuracy: 0.7267\n",
            "Epoch 786/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5419 - accuracy: 0.7267\n",
            "Epoch 787/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5422 - accuracy: 0.7200\n",
            "Epoch 788/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5414 - accuracy: 0.7200\n",
            "Epoch 789/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5419 - accuracy: 0.7133\n",
            "Epoch 790/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5432 - accuracy: 0.7133\n",
            "Epoch 791/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5408 - accuracy: 0.7200\n",
            "Epoch 792/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5416 - accuracy: 0.7200\n",
            "Epoch 793/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5427 - accuracy: 0.7200\n",
            "Epoch 794/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5407 - accuracy: 0.7200\n",
            "Epoch 795/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5421 - accuracy: 0.7200\n",
            "Epoch 796/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5407 - accuracy: 0.7200\n",
            "Epoch 797/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5411 - accuracy: 0.7200\n",
            "Epoch 798/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5410 - accuracy: 0.7200\n",
            "Epoch 799/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5412 - accuracy: 0.7200\n",
            "Epoch 800/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5404 - accuracy: 0.7200\n",
            "Epoch 801/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5410 - accuracy: 0.7267\n",
            "Epoch 802/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5398 - accuracy: 0.7200\n",
            "Epoch 803/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5405 - accuracy: 0.7200\n",
            "Epoch 804/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5403 - accuracy: 0.7200\n",
            "Epoch 805/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5404 - accuracy: 0.7200\n",
            "Epoch 806/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5412 - accuracy: 0.7133\n",
            "Epoch 807/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5406 - accuracy: 0.7200\n",
            "Epoch 808/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5392 - accuracy: 0.7200\n",
            "Epoch 809/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5390 - accuracy: 0.7200\n",
            "Epoch 810/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5400 - accuracy: 0.7200\n",
            "Epoch 811/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5397 - accuracy: 0.7200\n",
            "Epoch 812/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5396 - accuracy: 0.7200\n",
            "Epoch 813/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5390 - accuracy: 0.7267\n",
            "Epoch 814/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5392 - accuracy: 0.7267\n",
            "Epoch 815/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5388 - accuracy: 0.7267\n",
            "Epoch 816/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5398 - accuracy: 0.7200\n",
            "Epoch 817/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5388 - accuracy: 0.7200\n",
            "Epoch 818/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5385 - accuracy: 0.7267\n",
            "Epoch 819/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5397 - accuracy: 0.7267\n",
            "Epoch 820/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5385 - accuracy: 0.7267\n",
            "Epoch 821/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5394 - accuracy: 0.7200\n",
            "Epoch 822/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5385 - accuracy: 0.7267\n",
            "Epoch 823/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5383 - accuracy: 0.7200\n",
            "Epoch 824/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5383 - accuracy: 0.7267\n",
            "Epoch 825/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5376 - accuracy: 0.7200\n",
            "Epoch 826/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5384 - accuracy: 0.7200\n",
            "Epoch 827/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5388 - accuracy: 0.7200\n",
            "Epoch 828/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5388 - accuracy: 0.7267\n",
            "Epoch 829/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5375 - accuracy: 0.7267\n",
            "Epoch 830/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5371 - accuracy: 0.7200\n",
            "Epoch 831/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5382 - accuracy: 0.7267\n",
            "Epoch 832/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5367 - accuracy: 0.7200\n",
            "Epoch 833/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5370 - accuracy: 0.7200\n",
            "Epoch 834/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5373 - accuracy: 0.7267\n",
            "Epoch 835/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5376 - accuracy: 0.7200\n",
            "Epoch 836/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5370 - accuracy: 0.7200\n",
            "Epoch 837/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5389 - accuracy: 0.7200\n",
            "Epoch 838/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5370 - accuracy: 0.7267\n",
            "Epoch 839/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5380 - accuracy: 0.7267\n",
            "Epoch 840/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5373 - accuracy: 0.7267\n",
            "Epoch 841/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5371 - accuracy: 0.7133\n",
            "Epoch 842/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5364 - accuracy: 0.7200\n",
            "Epoch 843/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5364 - accuracy: 0.7200\n",
            "Epoch 844/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5367 - accuracy: 0.7200\n",
            "Epoch 845/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5360 - accuracy: 0.7200\n",
            "Epoch 846/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5377 - accuracy: 0.7267\n",
            "Epoch 847/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5361 - accuracy: 0.7267\n",
            "Epoch 848/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5363 - accuracy: 0.7200\n",
            "Epoch 849/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5356 - accuracy: 0.7267\n",
            "Epoch 850/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5355 - accuracy: 0.7267\n",
            "Epoch 851/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5356 - accuracy: 0.7200\n",
            "Epoch 852/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5359 - accuracy: 0.7200\n",
            "Epoch 853/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5354 - accuracy: 0.7267\n",
            "Epoch 854/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5359 - accuracy: 0.7267\n",
            "Epoch 855/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5355 - accuracy: 0.7267\n",
            "Epoch 856/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5358 - accuracy: 0.7200\n",
            "Epoch 857/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5352 - accuracy: 0.7200\n",
            "Epoch 858/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5351 - accuracy: 0.7267\n",
            "Epoch 859/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5343 - accuracy: 0.7267\n",
            "Epoch 860/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5350 - accuracy: 0.7267\n",
            "Epoch 861/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5342 - accuracy: 0.7200\n",
            "Epoch 862/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5356 - accuracy: 0.7267\n",
            "Epoch 863/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5337 - accuracy: 0.7267\n",
            "Epoch 864/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5345 - accuracy: 0.7267\n",
            "Epoch 865/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5346 - accuracy: 0.7267\n",
            "Epoch 866/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5345 - accuracy: 0.7267\n",
            "Epoch 867/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5337 - accuracy: 0.7267\n",
            "Epoch 868/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5344 - accuracy: 0.7333\n",
            "Epoch 869/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5345 - accuracy: 0.7200\n",
            "Epoch 870/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5339 - accuracy: 0.7267\n",
            "Epoch 871/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5340 - accuracy: 0.7267\n",
            "Epoch 872/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5331 - accuracy: 0.7267\n",
            "Epoch 873/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5330 - accuracy: 0.7267\n",
            "Epoch 874/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5339 - accuracy: 0.7200\n",
            "Epoch 875/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5334 - accuracy: 0.7267\n",
            "Epoch 876/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5328 - accuracy: 0.7267\n",
            "Epoch 877/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5322 - accuracy: 0.7200\n",
            "Epoch 878/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5332 - accuracy: 0.7267\n",
            "Epoch 879/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5321 - accuracy: 0.7333\n",
            "Epoch 880/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5328 - accuracy: 0.7333\n",
            "Epoch 881/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5335 - accuracy: 0.7267\n",
            "Epoch 882/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5331 - accuracy: 0.7333\n",
            "Epoch 883/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5315 - accuracy: 0.7333\n",
            "Epoch 884/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5327 - accuracy: 0.7333\n",
            "Epoch 885/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5320 - accuracy: 0.7400\n",
            "Epoch 886/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5322 - accuracy: 0.7267\n",
            "Epoch 887/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5322 - accuracy: 0.7333\n",
            "Epoch 888/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5315 - accuracy: 0.7333\n",
            "Epoch 889/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5314 - accuracy: 0.7333\n",
            "Epoch 890/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5317 - accuracy: 0.7400\n",
            "Epoch 891/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5323 - accuracy: 0.7333\n",
            "Epoch 892/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5309 - accuracy: 0.7333\n",
            "Epoch 893/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5317 - accuracy: 0.7267\n",
            "Epoch 894/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5316 - accuracy: 0.7267\n",
            "Epoch 895/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5314 - accuracy: 0.7333\n",
            "Epoch 896/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5311 - accuracy: 0.7333\n",
            "Epoch 897/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5324 - accuracy: 0.7333\n",
            "Epoch 898/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5315 - accuracy: 0.7400\n",
            "Epoch 899/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5308 - accuracy: 0.7333\n",
            "Epoch 900/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5310 - accuracy: 0.7333\n",
            "Epoch 901/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5304 - accuracy: 0.7400\n",
            "Epoch 902/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5299 - accuracy: 0.7400\n",
            "Epoch 903/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5305 - accuracy: 0.7333\n",
            "Epoch 904/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5304 - accuracy: 0.7400\n",
            "Epoch 905/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5302 - accuracy: 0.7333\n",
            "Epoch 906/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5298 - accuracy: 0.7333\n",
            "Epoch 907/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5308 - accuracy: 0.7333\n",
            "Epoch 908/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5296 - accuracy: 0.7400\n",
            "Epoch 909/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5302 - accuracy: 0.7400\n",
            "Epoch 910/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5291 - accuracy: 0.7333\n",
            "Epoch 911/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5305 - accuracy: 0.7333\n",
            "Epoch 912/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5292 - accuracy: 0.7333\n",
            "Epoch 913/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5285 - accuracy: 0.7267\n",
            "Epoch 914/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5303 - accuracy: 0.7333\n",
            "Epoch 915/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5292 - accuracy: 0.7333\n",
            "Epoch 916/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5297 - accuracy: 0.7333\n",
            "Epoch 917/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5286 - accuracy: 0.7400\n",
            "Epoch 918/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5297 - accuracy: 0.7267\n",
            "Epoch 919/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5284 - accuracy: 0.7267\n",
            "Epoch 920/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5288 - accuracy: 0.7333\n",
            "Epoch 921/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5292 - accuracy: 0.7333\n",
            "Epoch 922/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5288 - accuracy: 0.7333\n",
            "Epoch 923/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5297 - accuracy: 0.7333\n",
            "Epoch 924/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5281 - accuracy: 0.7333\n",
            "Epoch 925/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5286 - accuracy: 0.7333\n",
            "Epoch 926/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5285 - accuracy: 0.7333\n",
            "Epoch 927/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5278 - accuracy: 0.7267\n",
            "Epoch 928/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5282 - accuracy: 0.7333\n",
            "Epoch 929/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5286 - accuracy: 0.7267\n",
            "Epoch 930/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5279 - accuracy: 0.7333\n",
            "Epoch 931/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5286 - accuracy: 0.7267\n",
            "Epoch 932/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5274 - accuracy: 0.7333\n",
            "Epoch 933/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5275 - accuracy: 0.7333\n",
            "Epoch 934/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5273 - accuracy: 0.7333\n",
            "Epoch 935/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5273 - accuracy: 0.7333\n",
            "Epoch 936/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5263 - accuracy: 0.7333\n",
            "Epoch 937/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5268 - accuracy: 0.7333\n",
            "Epoch 938/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5265 - accuracy: 0.7333\n",
            "Epoch 939/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5273 - accuracy: 0.7333\n",
            "Epoch 940/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5266 - accuracy: 0.7333\n",
            "Epoch 941/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5273 - accuracy: 0.7400\n",
            "Epoch 942/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5260 - accuracy: 0.7333\n",
            "Epoch 943/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5273 - accuracy: 0.7333\n",
            "Epoch 944/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5279 - accuracy: 0.7400\n",
            "Epoch 945/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5266 - accuracy: 0.7333\n",
            "Epoch 946/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5253 - accuracy: 0.7333\n",
            "Epoch 947/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5257 - accuracy: 0.7333\n",
            "Epoch 948/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5259 - accuracy: 0.7400\n",
            "Epoch 949/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5254 - accuracy: 0.7400\n",
            "Epoch 950/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5265 - accuracy: 0.7333\n",
            "Epoch 951/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5254 - accuracy: 0.7333\n",
            "Epoch 952/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5252 - accuracy: 0.7333\n",
            "Epoch 953/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5245 - accuracy: 0.7400\n",
            "Epoch 954/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5254 - accuracy: 0.7400\n",
            "Epoch 955/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5255 - accuracy: 0.7267\n",
            "Epoch 956/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5247 - accuracy: 0.7333\n",
            "Epoch 957/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5248 - accuracy: 0.7267\n",
            "Epoch 958/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5246 - accuracy: 0.7400\n",
            "Epoch 959/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5239 - accuracy: 0.7333\n",
            "Epoch 960/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5248 - accuracy: 0.7333\n",
            "Epoch 961/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5241 - accuracy: 0.7333\n",
            "Epoch 962/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5239 - accuracy: 0.7400\n",
            "Epoch 963/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5247 - accuracy: 0.7333\n",
            "Epoch 964/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5248 - accuracy: 0.7400\n",
            "Epoch 965/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5244 - accuracy: 0.7333\n",
            "Epoch 966/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5238 - accuracy: 0.7400\n",
            "Epoch 967/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5240 - accuracy: 0.7333\n",
            "Epoch 968/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5233 - accuracy: 0.7400\n",
            "Epoch 969/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5231 - accuracy: 0.7333\n",
            "Epoch 970/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5232 - accuracy: 0.7400\n",
            "Epoch 971/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5227 - accuracy: 0.7400\n",
            "Epoch 972/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5233 - accuracy: 0.7400\n",
            "Epoch 973/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5233 - accuracy: 0.7267\n",
            "Epoch 974/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5236 - accuracy: 0.7333\n",
            "Epoch 975/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5227 - accuracy: 0.7400\n",
            "Epoch 976/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5230 - accuracy: 0.7400\n",
            "Epoch 977/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5233 - accuracy: 0.7333\n",
            "Epoch 978/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5220 - accuracy: 0.7400\n",
            "Epoch 979/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5223 - accuracy: 0.7400\n",
            "Epoch 980/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5224 - accuracy: 0.7400\n",
            "Epoch 981/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5222 - accuracy: 0.7400\n",
            "Epoch 982/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5222 - accuracy: 0.7400\n",
            "Epoch 983/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5217 - accuracy: 0.7400\n",
            "Epoch 984/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5230 - accuracy: 0.7400\n",
            "Epoch 985/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5219 - accuracy: 0.7400\n",
            "Epoch 986/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5222 - accuracy: 0.7400\n",
            "Epoch 987/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5222 - accuracy: 0.7333\n",
            "Epoch 988/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5207 - accuracy: 0.7400\n",
            "Epoch 989/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5221 - accuracy: 0.7400\n",
            "Epoch 990/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5216 - accuracy: 0.7400\n",
            "Epoch 991/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5209 - accuracy: 0.7400\n",
            "Epoch 992/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5201 - accuracy: 0.7400\n",
            "Epoch 993/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5207 - accuracy: 0.7400\n",
            "Epoch 994/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5203 - accuracy: 0.7400\n",
            "Epoch 995/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5210 - accuracy: 0.7467\n",
            "Epoch 996/1000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5200 - accuracy: 0.7400\n",
            "Epoch 997/1000\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5218 - accuracy: 0.7333\n",
            "Epoch 998/1000\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5204 - accuracy: 0.7400\n",
            "Epoch 999/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5203 - accuracy: 0.7400\n",
            "Epoch 1000/1000\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5199 - accuracy: 0.7400\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x792c042b2500>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Evaluation"
      ],
      "metadata": {
        "id": "HhYnMzbc2WWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix"
      ],
      "metadata": {
        "id": "wYK9fNWk2b-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gaussian Naive Bayes\n",
        "y_predict_bayes = nb_clf.predict(X_test_binary.values)\n",
        "\n",
        "print(classification_report(Y_test_binary,y_predict_bayes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Op_tNvRu5fvL",
        "outputId": "d63f9372-2200-433a-8db2-9835daa0e1bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.81      0.65        21\n",
            "           1       0.60      0.30      0.40        20\n",
            "\n",
            "    accuracy                           0.56        41\n",
            "   macro avg       0.57      0.55      0.53        41\n",
            "weighted avg       0.57      0.56      0.53        41\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM\n",
        "\n",
        "y_predict_svm = clf_svm.predict(X_test_binary.values)\n",
        "\n",
        "print(classification_report(Y_test_binary,y_predict_svm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_OWYVpsigOX",
        "outputId": "13217570-ae3b-4cf3-d7e5-4d839024f8d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.10      0.17        21\n",
            "           1       0.50      0.95      0.66        20\n",
            "\n",
            "    accuracy                           0.51        41\n",
            "   macro avg       0.58      0.52      0.41        41\n",
            "weighted avg       0.59      0.51      0.40        41\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random forest\n",
        "y_predict_rf = classifier_rf.predict(X_test_binary.values)\n",
        "\n",
        "print(classification_report(Y_test_binary,y_predict_rf))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fu1mMm2ioHPz",
        "outputId": "35b02fdc-616c-4fa6-8e07-cdc1fd4cfa73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.14      0.20        21\n",
            "           1       0.44      0.70      0.54        20\n",
            "\n",
            "    accuracy                           0.41        41\n",
            "   macro avg       0.39      0.42      0.37        41\n",
            "weighted avg       0.38      0.41      0.37        41\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest with XGB\n",
        "\n",
        "y_predict_xgb = xgb_random.predict(X_test_binary.values)\n",
        "\n",
        "print(classification_report(Y_test_binary,y_predict_xgb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WW4Q02Eoa0a",
        "outputId": "2e9f80ca-f47b-426f-c92c-e5c41a8921f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.33      0.38        21\n",
            "           1       0.44      0.55      0.49        20\n",
            "\n",
            "    accuracy                           0.44        41\n",
            "   macro avg       0.44      0.44      0.43        41\n",
            "weighted avg       0.44      0.44      0.43        41\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN\n",
        "y_predict_KNN = knn_clf.predict(X_test_binary.values)\n",
        "\n",
        "print(classification_report(Y_test_binary,y_predict_KNN))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KnXXTx3v8b3",
        "outputId": "7c3f2607-5e30-4cdb-826e-00d591bf3b51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.57      0.60        21\n",
            "           1       0.59      0.65      0.62        20\n",
            "\n",
            "    accuracy                           0.61        41\n",
            "   macro avg       0.61      0.61      0.61        41\n",
            "weighted avg       0.61      0.61      0.61        41\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perceptron\n",
        "\n",
        "y_predict_per = per_clf.predict(X_test_binary.values)\n",
        "print(classification_report(Y_test_binary,y_predict_per))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAz0L-lc8WEa",
        "outputId": "8d96ee88-8ffb-4a1a-b308-a0949bbdcb54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      1.00      0.68        21\n",
            "           1       0.00      0.00      0.00        20\n",
            "\n",
            "    accuracy                           0.51        41\n",
            "   macro avg       0.26      0.50      0.34        41\n",
            "weighted avg       0.26      0.51      0.35        41\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Stochastic Gradient Descent (SGD)\n",
        "\n",
        "y_predict_sgd = sgd_clf.predict(X_test_binary.values)\n",
        "\n",
        "print(classification_report(Y_test_binary,y_predict_sgd))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFHuknhn8WG4",
        "outputId": "f6036ce7-8a7a-40d7-9c9f-fbe28d9f0d36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        21\n",
            "           1       0.49      1.00      0.66        20\n",
            "\n",
            "    accuracy                           0.49        41\n",
            "   macro avg       0.24      0.50      0.33        41\n",
            "weighted avg       0.24      0.49      0.32        41\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Deep learning\n",
        "\n",
        "# Predict the probabilities for each class\n",
        "y_predict_deep_probabilities = deep_clf.predict(X_test_binary.values)\n",
        "y_predict_deep_probabilities = y_predict_deep_probabilities.flatten()  # Flatten the probabilities array\n",
        "\n",
        "# Convert probabilities to class labels\n",
        "y_predict_deep_labels = np.where(y_predict_deep_probabilities >= 0.5, 1, 0)\n",
        "\n",
        "# Print the classification report\n",
        "print(classification_report(Y_test_binary, y_predict_deep_labels))"
      ],
      "metadata": {
        "id": "JZ1jmDztfvIg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5acb198c-6bf3-4b16-ec3f-407987defe06"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x792c053cbe20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.14      0.25        21\n",
            "           1       0.53      1.00      0.69        20\n",
            "\n",
            "    accuracy                           0.56        41\n",
            "   macro avg       0.76      0.57      0.47        41\n",
            "weighted avg       0.77      0.56      0.46        41\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Analysis\n",
        "\n",
        "- Accuracy: all models below or equal 0.61\n",
        "-------------\n",
        "- Precision of down (0) :1 Deep learning vs 0 SGD\n",
        "- Precision of up (1) : 0.6 Bayes vs 0 Perceptron\n",
        "-------------\n",
        "- F1-score ( weighted average of precision and recall) of down (0): 0.68 Perceptron vs 0 SGD\n",
        "- F1-score ( weighted average of precision and recall) of up (1): 0.69 Deep learning vs 0 Perceptron\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fSWlcON9RZu1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if doing AND to Random forest vs KNN\n",
        "\n",
        "y_predict_combined_and = np.logical_and(y_predict_rf, y_predict_KNN).astype(int)\n",
        "y_predict_combined_and\n",
        "\n",
        "print(classification_report(NQ_test,y_predict_combined_and))"
      ],
      "metadata": {
        "id": "5r9Rkj9RdbQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if doing OR to Random forest vs KNN\n",
        "\n",
        "y_predict_combined_or = np.logical_or(y_predict_rf, y_predict_KNN).astype(int)\n",
        "y_predict_combined_or\n",
        "\n",
        "print(classification_report(NQ_test,y_predict_combined_or))"
      ],
      "metadata": {
        "id": "vnSQbXhgdemW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5ICHUQJ1digO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}